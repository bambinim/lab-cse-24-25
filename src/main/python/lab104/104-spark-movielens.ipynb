{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99b6b25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T15:34:09.444324Z",
     "iopub.status.busy": "2022-02-28T15:34:09.441785Z",
     "iopub.status.idle": "2022-02-28T15:34:10.302913Z",
     "shell.execute_reply": "2022-02-28T15:34:10.302209Z",
     "shell.execute_reply.started": "2022-02-28T15:34:09.444282Z"
    }
   },
   "source": [
    "# 104 Spark - Movielens\n",
    "\n",
    "The goal of this lab is to run some analysis on a different dataset, [MovieLens](https://grouplens.org/datasets/movielens/), on AWS.\n",
    "\n",
    "- [Spark programming guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
    "- [RDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/RDD.html)\n",
    "- [PairRDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/PairRDDFunctions.html)\n",
    "\n",
    "**Download the dataset** from [here](https://big.csr.unibo.it/downloads/bigdata/ml-dataset.zip), unzip it and put it in the ```datasets/big``` folder.\n",
    "\n",
    "- ml-movies.csv (<u>movieId</u>:Long, title:String, genres:String) \n",
    "    - genres are separated by pipelines  (e.g., \"comedy|drama|action\")\n",
    "    - each movie is associated with many ratings\n",
    "\n",
    "- ml-ratings.csv (<u>userId</u>:Long, <u>movieId</u>:Long, rating:Double, year:Int)\n",
    "    - each rating is associated with many tags\n",
    "    - ml-ratings-sample.csv is a small sample of ml-ratings.csv, useful for developing\n",
    "- ml-tags.csv (<u>userId</u>:Long, <u>movieId</u>:Long, <u>tag</u>:String, year:Int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2b673a91143a3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://BigData:4040\n",
       "SparkContext available as 'sc' (version = 3.5.1, master = local[*], app id = local-1732209136250)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6297e3f5-17d3-44ba-a06c-8b1acf0ca078",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_to_datasets: String = ../../../../datasets/big/\n",
       "path_ml_movies: String = ../../../../datasets/big/ml-movies.csv\n",
       "path_ml_ratings: String = ../../../../datasets/big/ml-ratings-sample.csv\n",
       "path_ml_tags: String = ../../../../datasets/big/ml-tags.csv\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path_to_datasets = \"../../../../datasets/big/\"\n",
    "\n",
    "val path_ml_movies = path_to_datasets + \"ml-movies.csv\"\n",
    "val path_ml_ratings = path_to_datasets + \"ml-ratings-sample.csv\"\n",
    "val path_ml_tags = path_to_datasets + \"ml-tags.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e643e27d-b710-43cb-bc3d-7bca65e93b15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import java.util.Calendar\n",
       "import org.apache.spark.sql.SaveMode\n",
       "import org.apache.spark.HashPartitioner\n",
       "defined object MovieLensParser\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.util.Calendar\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import org.apache.spark.HashPartitioner\n",
    "\n",
    "object MovieLensParser {\n",
    "\n",
    "  val noGenresListed = \"(no genres listed)\"\n",
    "  val commaRegex = \",(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "  val pipeRegex = \"\\\\|(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "  val quotes = \"\\\"\"\n",
    "  \n",
    "  /** Convert from timestamp (String) to year (Int) */\n",
    "  def yearFromTimestamp(timestamp: String): Int = {\n",
    "    val cal = Calendar.getInstance()\n",
    "    cal.setTimeInMillis(timestamp.trim.toLong * 1000L)\n",
    "    cal.get(Calendar.YEAR)\n",
    "  }\n",
    "\n",
    "  /** Function to parse movie records\n",
    "   *\n",
    "   *  @param line line that has to be parsed\n",
    "   *  @return tuple containing movieId, title and genres, none in case of input errors\n",
    "   */\n",
    "  def parseMovieLine(line: String): Option[(Long, String, String)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      var title = input(1).trim\n",
    "      title = if(title.startsWith(quotes)) title.substring(1) else title\n",
    "      title = if(title.endsWith(quotes)) title.substring(0, title.length - 1) else title\n",
    "      Some(input(0).trim.toLong, title, input(2).trim)\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /** Function to parse rating records\n",
    "   *\n",
    "   *  @param line line that has to be parsed\n",
    "   *  @return tuple containing userId, movieId, rating, and year none in case of input errors\n",
    "   */\n",
    "  def parseRatingLine(line: String): Option[(Long, Long, Double, Int)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      Some(input(0).trim.toLong, input(1).trim.toLong, input(2).trim.toDouble, yearFromTimestamp(input(3)))\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /** Function to parse tag records\n",
    "   *\n",
    "   *  @param line line that has to be parsed\n",
    "   *  @return tuple containing userId, movieId, tag, and year, none in case of input errors\n",
    "   */\n",
    "  def parseTagLine(line: String) : Option[(Long, Long, String, Int)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      Some(input(0).trim.toLong, input(1).trim.toLong, input(2), yearFromTimestamp(input(3)))\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e69ae6f-50f6-4e2f-9fe8-ff6d747e675f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddMovies: org.apache.spark.rdd.RDD[(Long, String, String)] = MapPartitionsRDD[2] at flatMap at <console>:32\n",
       "rddRatings: org.apache.spark.rdd.RDD[(Long, Long, Double, Int)] = MapPartitionsRDD[5] at flatMap at <console>:33\n",
       "rddTags: org.apache.spark.rdd.RDD[(Long, Long, String, Int)] = MapPartitionsRDD[8] at flatMap at <console>:34\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rddMovies = sc.textFile(path_ml_movies).flatMap(MovieLensParser.parseMovieLine)\n",
    "val rddRatings = sc.textFile(path_ml_ratings).flatMap(MovieLensParser.parseRatingLine)\n",
    "val rddTags = sc.textFile(path_ml_tags).flatMap(MovieLensParser.parseTagLine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dfbdfd-2ee7-4488-a95f-9f1f809e581c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T15:59:00.715374Z",
     "iopub.status.busy": "2022-02-28T15:59:00.715148Z",
     "iopub.status.idle": "2022-02-28T15:59:01.005430Z",
     "shell.execute_reply": "2022-02-28T15:59:01.004685Z",
     "shell.execute_reply.started": "2022-02-28T15:59:00.715351Z"
    },
    "tags": []
   },
   "source": [
    "## 104-1 Datasets exploration\n",
    "\n",
    "Cache the datasets and answer the following questions:\n",
    "\n",
    "- How many (distinct) users, movies, ratings, and tags?\n",
    "- How many (distinct) genres?\n",
    "- On average, how many ratings per user?\n",
    "- On average, how many ratings per movie?\n",
    "- On average, how many genres per movie?\n",
    "- What is the range of ratings?\n",
    "- Which years? (print an ordered list)\n",
    "- On average, how many ratings per year?\n",
    "\n",
    "Try these locally as \"extra\" exercises; solutions will be published later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f07a5b9-baaf-4564-8988-33e23ced42ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddMoviesCached: rddMovies.type = MapPartitionsRDD[2] at flatMap at <console>:32\n",
       "rddRatingsCached: rddRatings.type = MapPartitionsRDD[5] at flatMap at <console>:33\n",
       "rddTagsCached: rddTags.type = MapPartitionsRDD[8] at flatMap at <console>:34\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rddMoviesCached = rddMovies.cache()\n",
    "val rddRatingsCached = rddRatings.cache()\n",
    "val rddTagsCached = rddTags.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4016ac-cb34-48d0-a45c-29122e5fa59a",
   "metadata": {},
   "source": [
    "## 104-2 Compute the average rating for each movie\n",
    "\n",
    "- Export the result to a file\n",
    "- Do not start from cached RDDs\n",
    "- Evaluate:\n",
    "  - Join-and-Aggregate\n",
    "  - Aggregate-and-Join\n",
    "  - Aggregate-and-BroadcastJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feb49547-58f9-4994-929a-da867e2e4cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_output_avgRatPerMovie: String = ../../../../output/avgRatPerMovie\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path_output_avgRatPerMovie = \"../../../../output/avgRatPerMovie\"\n",
    "// rdd.coalesce(1).toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output_avgRatPerMovie)\n",
    "\n",
    "sc.getPersistentRDDs.foreach(_._2.unpersist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4fdb9c-7a73-43a0-a121-fe98dc71ea02",
   "metadata": {},
   "source": [
    "### Join-and-Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35060678-a714-4871-a0ee-bd6d1149c2c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddMoviesKV: org.apache.spark.rdd.RDD[(Long, String)] = MapPartitionsRDD[9] at map at <console>:30\n",
       "avgRatPerMovie: Unit = ()\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rddMoviesKV = rddMovies.map(x => (x._1,x._2))\n",
    "val avgRatPerMovie = rddRatings.\n",
    "    map(x => ((x._2),(x._3))).\n",
    "    join(rddMoviesKV).\n",
    "    map({case (m,(r,t)) => ((m,t),r)}).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v, a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2)).\n",
    "    map({case ((m,t),(sum,cnt)) => (m, t, sum/cnt, cnt)}).\n",
    "    coalesce(1).\n",
    "    toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output_avgRatPerMovie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a78f233f9cdaf",
   "metadata": {},
   "source": [
    "### Aggregate-and-Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45bddac2-b5b0-4eee-b34d-312877a7262e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddMoviesKV: org.apache.spark.rdd.RDD[(Long, String)] = MapPartitionsRDD[21] at map at <console>:31\n",
       "avgRatPerMovie: Unit = ()\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rddMoviesKV = rddMovies.map(x => (x._1,x._2))\n",
    "val avgRatPerMovie = rddRatings.\n",
    "    map(x => (x._2,x._3)).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v, a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2)).\n",
    "    mapValues({case (sum,cnt) => (sum/cnt, cnt)}).\n",
    "    join(rddMoviesKV).\n",
    "    map({case (m,((r,cnt),t)) => (m,t,r,cnt)}).\n",
    "    coalesce(1).\n",
    "    toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output_avgRatPerMovie)\n",
    "\n",
    "//avgRatPerMovie.toDebugString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887bbb2f-5b97-4918-ae8c-dd98f252a6e6",
   "metadata": {},
   "source": [
    "### Aggregate-and-BroadcastJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d17c7e50-802a-46e7-b522-2269e23c0085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddMoviesKV: org.apache.spark.rdd.RDD[(Long, String)] = MapPartitionsRDD[33] at map at <console>:32\n",
       "bRddMovies: org.apache.spark.broadcast.Broadcast[scala.collection.Map[Long,String]] = Broadcast(11)\n",
       "avgRatPerMovie: Unit = ()\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rddMoviesKV = rddMovies.map(x => (x._1,x._2))\n",
    "val bRddMovies = sc.broadcast(rddMoviesKV.collectAsMap())\n",
    "val avgRatPerMovie = rddRatings.\n",
    "    map(x => ((x._2),(x._3))).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v, a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2)).\n",
    "    mapValues({case (sum,cnt) => (sum/cnt, cnt)}).\n",
    "    map({case (m,(r,cnt)) => (m,bRddMovies.value.get(m),r,cnt)}).\n",
    "    coalesce(1).\n",
    "    toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output_avgRatPerMovie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07050d2-4447-4765-814d-2cd0ff1402c1",
   "metadata": {},
   "source": [
    "## 104-3 Compute the average rating for each genre\n",
    "\n",
    "Two possible workflows:\n",
    "\n",
    "1. Pre-aggregation (3 shuffles)\n",
    "\n",
    "  - Aggregate ratings by movieId\n",
    "  - Join with movies and map to genres\n",
    "  - Aggregate by genres\n",
    "  \n",
    "2. Join & aggregate (2 shuffles)\n",
    "\n",
    "  - Join with movies and map to genres\n",
    "  - Aggregate by genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3d4a4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: Array[(String, Double)] = Array((War,3.783042491587761), (Fantasy,3.507156227888689), (Western,3.561060510887772), (Musical,3.5266599723860925), (Horror,3.2769895869582677), (Crime,3.670028609274728), (Animation,3.581918830473744), (Thriller,3.5139459591764077), (Adventure,3.5102944364945143), (Action,3.455352917746147), (IMAX,3.635422788950502), (Children,3.417999182386264), (Sci-Fi,3.469121237733014), (Comedy,3.412333049956375), (Documentary,3.6519604052277472), (Mystery,3.6618355356062136), ((no genres listed),3.2050147492625367), (Romance,3.537282367016482), (Drama,3.666335509188491), (Film-Noir,3.909257375381485))\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddRatings\n",
    "  .map({case (_, movieId, rating, _) => (movieId, (rating, 1))})\n",
    "  .reduceByKey((x, y) => (x._1 + y._1, x._2 + y._2))\n",
    "  .join(rddMovies.map({case (movieId, title, genres) => ((movieId, genres))}).flatMapValues(_.split(\"\"\"\\|\"\"\")))\n",
    "  .map({case (movieId, ((rating, count), genre)) => (genre, (rating, count))})\n",
    "  .reduceByKey((x, y) => (x._1 + y._1, x._2 + y._2))\n",
    "  .map({case (genre, (rating, count)) => (genre, rating / count)})\n",
    "  .collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83e35428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res9: Array[(String, Double)] = Array((War,3.783042491587761), (Fantasy,3.507156227888689), (Western,3.561060510887772), (Musical,3.5266599723860925), (Horror,3.2769895869582677), (Crime,3.670028609274728), (Animation,3.581918830473744), (Thriller,3.5139459591764077), (Adventure,3.5102944364945143), (Action,3.455352917746147), (IMAX,3.635422788950502), (Children,3.417999182386264), (Sci-Fi,3.469121237733014), (Comedy,3.412333049956375), (Documentary,3.6519604052277472), (Mystery,3.6618355356062136), ((no genres listed),3.2050147492625367), (Romance,3.537282367016482), (Drama,3.666335509188491), (Film-Noir,3.909257375381485))\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddRatings\n",
    "  .map({case (_, movieId, rating, _) => (movieId, rating)})\n",
    "  .join(rddMovies.map({case (movieId, title, genres) => ((movieId, genres))}))\n",
    "  .flatMap({case (movieId, (rating, genres)) => genres.split(\"\"\"\\|\"\"\").map(g => (g, (rating, 1)))})\n",
    "  .reduceByKey((x, y) => (x._1 + y._1, x._2 + y._2))\n",
    "  .map({case (genre, (rating, count)) => (genre, rating / count)})\n",
    "  .collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a8f82-2006-49a6-9a99-9de6638df74a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val path_output_avgRatPerGenre = \"s3a://\"+bucketname+\"/spark/avgRatPerGenre\"\n",
    "\n",
    "for ((k,v) <- sc.getPersistentRDDs) {\n",
    "  v.unpersist()\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
