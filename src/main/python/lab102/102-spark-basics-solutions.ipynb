{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd7243a-b7d3-4e47-b3ec-49cafdebada5",
   "metadata": {},
   "source": [
    "# 102 Spark basics\n",
    "\n",
    "The goal of this lab is to get familiar with Spark programming.\n",
    "\n",
    "- [Spark programming guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
    "- [RDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/RDD.html)\n",
    "- [PairRDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/PairRDDFunctions.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11bb4f39692d0432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:12:01.893550Z",
     "start_time": "2024-10-20T13:11:46.380948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://ISI-GALLINUCCI2.lan:4040\n",
       "SparkContext available as 'sc' (version = 3.5.1, master = local[*], app id = local-1729429916747)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e281923de95ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "// DO NOT EXECUTE - this is needed just to avoid showing errors in the following cells\n",
    "val sc = spark.SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a0be28e5e823",
   "metadata": {},
   "source": [
    "## 102-1 Spark warm-up\n",
    "\n",
    "Load the ```capra``` and ```divinacommedia``` datasets and try the following actions:\n",
    "- Show their content (```collect```)\n",
    "- Count their rows (```count```)\n",
    "- Split phrases into words (```map``` or ```flatMap```; what’s the difference?)\n",
    "- Check the results (remember: evaluation is lazy)\n",
    "- Try the ```toDebugString``` function to check the execution plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc4b5cee4a93755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:25:49.644422Z",
     "start_time": "2024-10-20T13:25:49.169096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddCapra: org.apache.spark.rdd.RDD[String] = ../../../../datasets/capra.txt MapPartitionsRDD[1] at textFile at <console>:25\r\n",
       "rddDC: org.apache.spark.rdd.RDD[String] = ../../../../datasets/divinacommedia.txt MapPartitionsRDD[3] at textFile at <console>:26\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rddCapra = sc.textFile(\"../../../../datasets/capra.txt\")\n",
    "val rddDC = sc.textFile(\"../../../../datasets/divinacommedia.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df92012331ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "val rddCapraWords1 = rddCapra.map( x => x.split(\" \") )\n",
    "rddCapraWords1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c9837173b267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rddCapraWords1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b58790bcfd931",
   "metadata": {},
   "outputs": [],
   "source": [
    "val rddCapraWords2 = rddCapra.flatMap( x => x.split(\" \") )\n",
    "rddCapraWords2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf925abda9b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rddCapraWords2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a1761200725bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val rddL = rddCapra.\n",
    "   flatMap( x => x.split(\" \") ).\n",
    "   map(x => (x,1)).\n",
    "   reduceByKey((x,y)=>x+y)\n",
    "rddL.toDebugString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d04659ace472d8",
   "metadata": {},
   "source": [
    "## 102-2 Basic Spark jobs\n",
    "\n",
    "Implement on Spark the following jobs and test them on both capra and divinacommedia datasets.\n",
    "\n",
    "- **Word count**: count the number of occurrences of each word\n",
    "  - Result: (sopra, 1), (la, 4), …\n",
    "- **Word length count**: count the number of occurrences of words of given lengths\n",
    "  - Result: (2, 4), (5, 8)\n",
    "- Count the average length of words given their first letter (i.e., words that begin with \"s\" have an average length of 5)\n",
    "  - Result: (s, 5), (l, 2), …\n",
    "- Return the inverted index of words (i.e., for each word, list the numbers of lines in which they appear)\n",
    "  - Result: (sopra, (0)), (la, (0, 1)), ...\n",
    "\n",
    "Also, check how sorting works and try to sort key-value RDDs by descending values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab6b26a927a7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Word count\n",
    "\n",
    "rddCapra.\n",
    "  flatMap( x => x.split(\" \") ).\n",
    "  map( x => (x,1)).\n",
    "  reduceByKey((x,y) => x + y).\n",
    "  collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a163112f6f1996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Word length count\n",
    "\n",
    "rddCapra.\n",
    "  flatMap( x => x.split(\" \") ).\n",
    "  map( x => (x.length,1)).\n",
    "  reduceByKey((x,y) => x + y).\n",
    "  collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f920336ead88eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Average word length by initial\n",
    "\n",
    "rddCapra.\n",
    "  flatMap( x => x.split(\" \") ).\n",
    "  filter( _.length>0 ).\n",
    "  map( x => (x.substring(0,1).toLowerCase, (1.0,x.length.toDouble))).\n",
    "  reduceByKey((x, y) => (x._1 + y._1, x._2 + y._2)).\n",
    "  mapValues(v => v._2/v._1).\n",
    "  collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2a91002beea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Inverted index (word-based offset)\n",
    "\n",
    "rddCapra.\n",
    "  flatMap( x => x.split(\" \") ).\n",
    "  zipWithIndex().\n",
    "  groupByKey().\n",
    "  collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2686f5c972e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Inverted index (sentence-based offset)\n",
    "rddCapra.\n",
    "  zipWithIndex().\n",
    "  flatMap({case (k,v)=> k.split(\" \").map(x=>(x,v))}).\n",
    "  distinct().\n",
    "  groupByKey().\n",
    "  collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa65d30adec9ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Inverted index (sentence-based offset) alternative\n",
    "val rddMap = rddCapra.zipWithIndex().\n",
    "    map({case (k,v)=>(v,k)}).\n",
    "    flatMapValues( x => x.split(\" \") ).\n",
    "    map({case (k,v)=>(v,k)}).\n",
    "    distinct().\n",
    "    groupByKey().\n",
    "    collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc58c9249e33b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Word count sorted by key\n",
    "\n",
    "rddCapra.\n",
    "  flatMap( x => x.split(\" \") ).\n",
    "  map( x => (x,1)).\n",
    "  reduceByKey((x,y) => x + y).\n",
    "  sortByKey().\n",
    "  collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c973a76ab7494260",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Word count sorted by descending values\n",
    "\n",
    "rddCapra.\n",
    "  flatMap( x => x.split(\" \") ).\n",
    "  map( x => (x,1)).\n",
    "  reduceByKey((x,y) => x + y).\n",
    "  map({case (k,v)=>(v,k)}).\n",
    "  sortByKey(false).\n",
    "  map({case (k,v)=>(v,k)}).\n",
    "  collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c49c3689d65e2",
   "metadata": {},
   "source": [
    "## 103-3 Extra Spark jobs\n",
    "\n",
    "Implement the following job.\n",
    "\n",
    "- Co-occurrence count: count the number of co-occurrences in the text. A co-occurrence is defined as \"two distinct words appearing in the same line\".\n",
    "  - In the first line of the *capra* dataset, co-occurrences are:\n",
    "     - (sopra, la), (sopra, panca), (sopra, capra), (sopra, campa)\n",
    "     - (la, sopra), (la, panca), (la, capra), (la, campa) \n",
    "     - (panca, sopra), (panca, la), (panca, capra), (panca, campa)\n",
    "     - (capra, sopra), (capra, la), (capra, panca), (capra, campa)\n",
    "     - (campa, sopra), (campa, la), (campa, panca), (campa, capra)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
