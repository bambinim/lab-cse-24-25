{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd7243a-b7d3-4e47-b3ec-49cafdebada5",
   "metadata": {},
   "source": [
    "# 102 Spark basics\n",
    "\n",
    "The goal of this lab is to get familiar with Spark programming.\n",
    "\n",
    "- [Spark programming guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
    "- [RDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/RDD.html)\n",
    "- [PairRDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/PairRDDFunctions.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11bb4f39692d0432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://BigData:4040\n",
       "SparkContext available as 'sc' (version = 3.5.1, master = local[*], app id = local-1729585476417)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a0be28e5e823",
   "metadata": {},
   "source": [
    "## 102-1 Spark warm-up\n",
    "\n",
    "Load the ```capra``` and ```divinacommedia``` datasets and try the following actions:\n",
    "- Show their content (```collect```)\n",
    "- Count their rows (```count```)\n",
    "- Split phrases into words (```map``` or ```flatMap```; what’s the difference?)\n",
    "- Check the results (remember: evaluation is lazy)\n",
    "- Try the ```toDebugString``` function to check the execution plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb895001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddCapra: org.apache.spark.rdd.RDD[String] = /home/bambinim/projects/lab-cse-24-25/datasets/capra.txt MapPartitionsRDD[11] at textFile at <console>:26\n",
       "capraCollected: Array[String] = Array(sopra la panca la capra campa, sotto la panca la capra crepa)\n",
       "capraCount: Long = 2\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rddCapra = sc.textFile(\"/home/bambinim/projects/lab-cse-24-25/datasets/capra.txt\")\n",
    "val capraCollected = rddCapra.collect\n",
    "val capraCount = rddCapra.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "961415bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddDivina: org.apache.spark.rdd.RDD[String] = /home/bambinim/projects/lab-cse-24-25/datasets/divinacommedia.txt MapPartitionsRDD[15] at textFile at <console>:26\n",
       "divinaCollected: Array[String] = Array(LA DIVINA COMMEDIA, di Dante Alighieri, INFERNO, \"\", \"\", \"\", Inferno: Canto I, \"\", \"  Nel mezzo del cammin di nostra vita\", mi ritrovai per una selva oscura, ch� la diritta via era smarrita., \"  Ahi quanto a dir qual era � cosa dura\", esta selva selvaggia e aspra e forte, che nel pensier rinova la paura!, \"  Tant'� amara che poco � pi� morte;\", ma per trattar del ben ch'i' vi trovai,, dir� de l'altre cose ch'i' v'ho scorte., \"  Io non so ben ridir com'i' v'intrai,\", tant'era pien di sonno a quel punto, che la verace via abbandonai., \"  Ma poi ch'i' fui al pi� d'un colle giunto,\", l� dove te...\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rddDivina = sc.textFile(\"/home/bambinim/projects/lab-cse-24-25/datasets/divinacommedia.txt\")\n",
    "val divinaCollected = rddDivina.collect\n",
    "val divinaCount = rddDivina.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "102e50bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res11: Array[String] = Array(sopra, la, panca, la, capra, campa, sotto, la, panca, la, capra, crepa)\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCapra.flatMap(_.split(\" \")).collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d04659ace472d8",
   "metadata": {},
   "source": [
    "## 102-2 Basic Spark jobs\n",
    "\n",
    "Implement on Spark the following jobs and test them on both capra and divinacommedia datasets.\n",
    "\n",
    "- **Word count**: count the number of occurrences of each word\n",
    "  - Result: (sopra, 1), (la, 4), …\n",
    "- **Word length count**: count the number of occurrences of words of given lengths\n",
    "  - Result: (2, 4), (5, 8)\n",
    "- Count the average length of words given their first letter (i.e., words that begin with \"s\" have an average length of 5)\n",
    "  - Result: (s, 5), (l, 2), …\n",
    "- Return the inverted index of words (i.e., for each word, list the numbers of lines in which they appear)\n",
    "  - Result: (sopra, (0)), (la, (0, 1)), ...\n",
    "\n",
    "Also, check how sorting works and try to sort key-value RDDs by descending values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3be6add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wordCount: (rdd: org.apache.spark.rdd.RDD[String])org.apache.spark.rdd.RDD[(String, Int)]\n",
       "wordLengthCount: (rdd: org.apache.spark.rdd.RDD[String])org.apache.spark.rdd.RDD[(Int, Int)]\n",
       "averageWordLength: (rdd: org.apache.spark.rdd.RDD[String])org.apache.spark.rdd.RDD[(String, Int)]\n"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wordCount(rdd: org.apache.spark.rdd.RDD[String]): org.apache.spark.rdd.RDD[(String, Int)] =\n",
    "    rdd.flatMap(_.split(\" \")).filter(_.length > 0).map((_, 1)).reduceByKey(_+_)\n",
    "\n",
    "def wordLengthCount(rdd: org.apache.spark.rdd.RDD[String]): org.apache.spark.rdd.RDD[(Int, Int)] =\n",
    "    rdd.flatMap(_.split(\" \")).filter(_.length > 0).map(x => (x.length, 1)).reduceByKey(_+_)\n",
    "\n",
    "def averageWordLength(rdd: org.apache.spark.rdd.RDD[String]): org.apache.spark.rdd.RDD[(String, Int)] =\n",
    "    rdd.flatMap(_.split(\" \")).filter(_.length > 0).map(x => (x.take(1), (x.length, 1)))\n",
    "        .reduceByKey((x, y) => (x._1 + y._1, x._2 + y._2)).map(x => (x._1, x._2._1 / x._2._2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
